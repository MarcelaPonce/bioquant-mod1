enem_df<- readRDS("enem_df.RDS")
enem_df = select(enem_df, NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)
summarise(enem_df,media= mean (NU_NOTA_REDACAO, na.rm +TRUE))
enem_df<- readRDS("enem_df.RDS")
enem_df = select(enem_df, NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)
summarise(enem_df,media= mean (NU_NOTA_REDACAO, na.rm +TRUE))
summarise(enem_df,media= mean (NU_NOTA_REDACAO, na.rm = TRUE))
sample_n(enem_df, 12317)
sample_frac(enem_df, 0.01)
Grupo <- group_by(enem_df, TP_ESCOLA)
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm=TRUE))
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm = TRUE))
Grupo
Gruoi
Grupo
library(ggplot)
library(ggplot2)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title+"Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
mutate (enem_df, MEDI = (NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDI, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
enem_df = mutate (enem_df, MEDIA = (NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm = TRUE))
library(ggplot2)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
enem_df = mutate (enem_df, MEDIA = (NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm = TRUE))
library(ggplot2)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
enem_df = mutate (enem_df, MEDIA = (NU_INSCRICAO, NU_IDADE, TP_ESCOLA, NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)/5)
enem_df = mutate (enem_df, MEDIA = (NU_NOTA_CN:NU_NOTA_MT, NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm = TRUE))
library(ggplot2)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
enem_df = mutate (enem_df, MEDIA = (NU_NOTA_CN+ NU_NOTA_CH, NU_NOTA_LC+ NU_NOTA_MT + NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
summarise(Grupo, count= n(), media=mean(MEDIA< na.rm = TRUE))
summarise(Grupo, count= n(), MEDIA=mean(MEDIA< na.rm = TRUE))
enem_df = mutate (enem_df, MEDIA = (NU_NOTA_CN+ NU_NOTA_CH+ NU_NOTA_LC+ NU_NOTA_MT + NU_NOTA_REDACAO)/5)
sample_frac(enem_df, 0.01)
ggplot(data= enem_df, aes(x= as.character(TP_ESCOLA), y=MEDIA, fill = as.character(TP_ESCOLA)))+
geom_boxplot()+
labs(title="Desempenho por Tipo de Escola",x="Tipo de Escola", y="Desempenho",fill="Tipo")
library(dplyr,readxl,writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Lenth, Species)%>%
group_by (Species)
summarise (media= mean(Petal.Length),
max = max(Petal. Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
Write_xlsx("estatisticas.xlsx")
library(dplyr,readxl,writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Lenth, Species)%>%
group_by (Species)
summarise (media= mean(Petal.Length),
max = max(Petal. Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
write_xlsx("estatisticas.xlsx")
library(dplyr,readxl,writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Lenth, Species)%>%
group_by (Species)
library(dplyr)
library(readxl)
library(writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Lenth, Species)%>%
group_by (Species)
summarise (media= mean(Petal.Length),
max = max(Petal. Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
write_xlsx("estatisticas.xlsx")
group_by (Species) %>%
summarise (media= mean(Petal.Length),
max = max(Petal. Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
write_xlsx("estatisticas.xlsx")
library(dplyr)
library(readxl)
library(writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Lenth, Species)%>%
group_by (Species) %>%
summarise (media= mean(Petal.Length),
max = max(Petal.Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
write_xlsx("estatisticas.xlsx")
library(dplyr)
library(readxl)
library(writexl)
read_xlsx(readxl_example("datasets.xlsx"), "iris")%>%
select(Petal.Length, Species)%>%
group_by (Species) %>%
summarise (media= mean(Petal.Length),
max = max(Petal.Length),
min= min(Petal.Length),
mediana = median(Petal.Length))%>%
write_xlsx("estatisticas.xlsx")
readxl_example()
arq<- readxl_example("datasets.xlsx")
arq
dados<-read_xlsx(arq, "iris")
library(writexl)
write_xlsx(iris,"teste.xlsx")
write_xlsx(list("plan1_iris"=iris, "plan2_women"=women),"teste2.xlsx")
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_point()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_abline()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_area()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_bar()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_bin2d()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_point()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg, color= as.factor(am)))+
geom_point()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg, color= as.factor(am)))+
geom_point()
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg, color= as.factor(am)))+
geom_histogram(color="black", fill="orange")
library(ggplot2)
ggplot(data= mtcars, aes(x= disp,y= mpg))+
geom_histogram(color="black", fill="orange")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="orange")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="pink")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="blue")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="burgundy")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="lilac")
library(ggplot2)
ggplot(data= mtcars, aes(x= as.factor(cyl)))+
geom_bar(color="black", fill="purple")
library(ggplot2)
ggplot(data= mtcars, aes(x= hp, y=mpg, fill= as.factor(am)(cyl)))+
geom_point(shape= 12)
library(ggplot2)
ggplot(data= mtcars, aes(x= hp, y=mpg, fill= as.factor(am),(cyl)))+
geom_point(shape= 12)
install.packages(multcompView)
library(readxl)
library(ggfortify)
library(factoextra)
library(readxl)
tabela_R_let�_cia <- read_excel("C:/Users/User/Downloads/tabela R - letícia.xlsx")
View(tabela_R_let�_cia)
library(readxl)
tabela_R_let�_cia <- read_excel("C:/Users/User/Downloads/tabela R - letícia.xlsx")
View(tabela_R_let�_cia)
library(readxl)
aula_R <- read_excel("C:/Users/User/Downloads/aula.R.xlsx")
View(aula_R)
pcal<- read_excel(aula_R <- read_excel("C:/Users/User/Downloads/aula.R.xlsx", sheet = "pca")
pca<- na.omit(pca1)
pca<- na.omit(pca1)
pcal<- read_excel("C:/Users/User/Downloads/aula.R.xlsx", sheet = "pca")
pca<- na.omit(pca1)
pca1<- read_excel("C:/Users/User/Downloads/aula.R.xlsx", sheet = "pca")
pca<- na.omit(pca1)
View(pcal)
pca_esca <- scale (pca[,c(5,14,21:30)])
PCAmodel<- prcomp (pca_esca)
fviz_contrib(PCAmodel, choice = "var", axes = 1, top = 10)
fviz_contrib(PCAmodel, choice = "var", axes = 2, top = 10)
PCAplot<- autoplot(PCAmodel,data = pca)
PCAplot<- autoplot(PCAmodel,data = pca, colour= "tratamento", loadings=TRUE, loadings.label=TRUE, frame=TRUE)
PCAplot<- autoplot(PCAmodel,data = pca, colour= "tratamento",
loadings=TRUE, loadings.label=TRUE, frame=TRUE)
PCAplot<- autoplot(PCAmodel,data = pca, colour= "tratamento",
loadings=TRUE, loadings.label=TRUE, frame=TRUE)
PCAplot<- autoplot(PCAmodel, data = pca, colour= "tratamento",
loadings=TRUE, loadings.label=TRUE, frame=TRUE)
fviz_contrib(PCAmodel, choice = "var", axes = 1, top = 10)
fviz_contrib(PCAmodel, choice = "var", axes = 2, top = 10)
fviz_contrib(PCAmodel, choice = "var", axes = 1:2, top = 10)
PCAplot<- autoplot(PCAmodel, data = pca, colour= "tratamento",
loadings=TRUE, loadings.label=TRUE, frame=TRUE)
PCAplot
require(vegan)
require(viridis)
require(lawstat)
require(scales)
require(FD)
library(picante)
require(SYNCSA)
library(pairwiseAdonis)
ab_cv <- read.delim("C:/Users/User/Downloads/ab_cv.txt")
View(ab_cv)
ab_cv <- read.table ("ab_cv.txt",h = T)
View(ab_cv)
View(ab_cv)
ab_cv <- read.delim("C:/Users/User/Downloads/ab_cv.txt")
View(ab_cv)
ab_cv <- read.table ("ab_cv",h = T)
c9<- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3):
length(c9$das)
# Analise de dados de vegetacao
# Analise da estrutura, composicao de especies e composicao funcional
setwd("C:/Users/Waira/Google Drive/Pratica em R/Pratica vegetacao")
View(pcal)
View(pcal)
rm(pcal)
setwd("C:\Users\User\Documents\R\ab_cv")
library(readr)
ab_cv <- read_csv("R/ab_cv.txt")
View(ab_cv)
library(readr)
ab_cv <- read_csv("R/ab_cv.txt")
require(vegan)
require(viridis)
require(lawstat)
require(scales)
require(FD)
library(picante)
require(SYNCSA)
library(pairwiseAdonis)
ab_cv
ab_cv <- read.table ("ab_cv",h = T)
ab_cv
ab_cv <- read_csv("R/ab_cv.txt")
setwd("C:\Users\User\Documents\R\ab_cv")
setwd("C:\Users\User\Documents\R\ab_cv")
setwd("C:\\Users\\User\\Documents\\R\\ab_cv")
ab_cv <- read_csv("R/ab_cv.txt")
ab_cv
ab_cv <- read.table ("ab_cv",h = T)
ab_cv <- read.table ("R/ab_cv.txt",h = T)
class_cv <- c("5-9.3cm","9.4-13.7cm","13.8-18.1cm",
"18.2-22.5cm","22.6-26.8cm","26.9-31.2cm", ">31.3cm")
anos <- levels(factor(ab_cv$ano))
anos1<- c(rep(c("2008", "2019"), each= 10))
ab19<- subset(ab_cv,ab_cv$ano == "2019")
c9<- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3):
length(c9$das) # 2280 indivíduos da classe 1 em 2019
View(ab19)
c9<- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3):
length(c9$das)
c9<- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3):
length(c9$das) # 2280 indivíduos da classe 1 em 2019
c9.1 <- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3):
length(c9$das)
c9.1 <- subset(ab19, ab19$das >= 5 & ab19$das <= 9.3)
length(c9$das
c9.3<- subset(ab19, ab19$das >= 13.8 & ab19$das <= 18.1)
length(c9.3$das) #192 ind da classe 3 em 2019
c9.2 <- subset(ab19, ab19$das >= 9.4 & ab19$das <= 13.7)
length(c9.2$das)
c9.3 <- subset(ab19, ab19$das >= 13.8 & ab19$das <= 18.1)
length(c9.3$das)
c9.4 <- subset(ab19, ab19$das >= 18.2 & ab19$das <= 22.5)
length(c9.4$das)
c9.5 <- subset(ab19, ab19$das >= 22.6 & ab19$das <= 26.8)
length(c9.5$das)
c9.6 <- subset(ab19, ab19$das >= 26.9 & ab19$das <= 31.2)
length(c9.6$das)
c9.7 <- subset(ab19, ab19$das >= 31.3)
length(c9.7$das)
nporclasse <- c(2280, 541, 192, 66, 15, 8, 10)
diam19 <- data.frame(classe = class_cv, n.ind + nporclasse)
diam19 <- data.frame(classe = class_cv, n.ind + nporclasse)
diam19 <- data.frame(classe = class_cv, n, ind + nporclasse)
barplot(diam19.ind, names.arg = diam19$classe,
col = rainbow(7), las= 2, #cores e eixos
ylab = "densidade (ind/ha)")
diam19<- data.frame(classe = class_cv, n.ind + nporclasse)
diam19 <- data.frame(classe = class_cv n.ind + nporclasse)
diam19 <- data.frame(classe = class_cv. n.ind + nporclasse)
library(readxl)
exercicio_anova_1 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-1.xlsx")
View(exercicio_anova_1)
library(readxl)
exercicio_anova_2 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-2.xlsx")
View(exercicio_anova_2)
View(exercicio_anova_1)
jatoba <- c(17, 11, 16, 12)
cagaita <- c(13, 18, 16, 17)
copaiba <- c(16, 16, 19, 21)
araticum <- c(15, 12, 15, 14)
baru <- c(17, 11, 16, 12)
# Criando as variaveis dependentes
prod <- c(jatoba, cagaita, copaiba, araticum, baru)
help(fat)
fat <- c(rep("jatoba", 4), rep("cagaita", 4), rep("copaiba", 4),
rep("araticum", 4), rep("baru", 4))
# data.frame
frutos <- data.frame(fat, prod)
View(frutos)
# Visualisemos nossos dados...
plot(prod ~ fat, data = frutos)
# Premissas
# 1. Normalidade
shapiro.test(jatoba)
shapiro.test(cagaita)
shapiro.test(copaiba)
shapiro.test(araticum)
shapiro.test(baru)
# 2. Homocedasticidade
# Usaremos o test de levene que calcula a homocedasticidade
# H0 = variancia entre os grupos igual
# levene.test(y = vetor numerico, group = fator dos dados)
install.packages("lawstat")
library(lawstat)
levene.test(frutos$prod, group = frutos$fat)
# Finalmente a ANOVA one way!
# aov(formula = y variando em relacao a X, data = tabela)
resultado <- aov(prod ~ fat, data = frutos)
summary(resultado)
# variavel dependente
tingui <- c(16, 13, 19, 9, 15, 11, 22, 25, 17, 10, 11, 9, 13, 14, 21)
barbatimao <- c(18, 17, 21, 15, 13, 12, 14, 16, 12, 11, 8, 22, 7, 15, 10)
tamboril <- c(14, 12, 13, 7, 12, 9, 11, 14, 12, 5, 10, 8, 9, 4, 10)
ipe <- c(21, 20, 16, 15, 16, 21, 25, 17, 14, 22, 15, 21, 20, 23, 21)
prod2 <- c(tingui, barbatimao, tamboril, ipe)
prod2
prod2 <- c(tingui, barbatimao, tamboril, ipe)
prod2
fat2 <- rep(c(rep("tingui", 15), rep("barbatimao",15),
rep("tamboril", 15), rep("ipe", 15)))
fat2
local <- rep(c(rep("grandesertao",5), rep("veadeiros",5),
rep("brasilia",5)),4)
local
frutos2 <- data.frame(fat2, local, prod2)
frutos2
par(mfrow = c(1,2))
plot(prod2 ~ fat2+local, data = frutos2)
exercicio_anova_1 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-1.xlsx")
View(exercicio_anova_1)
library(readxl)
exercicio_anova_1 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-1.xlsx")
View(exercicio_anova_1)
# A planilha com os dados REFERENTES A ESSA QUESTAO e o exercicio-anova-1.xlsx
library(readxl)
exercicio_anova_1 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-1.xlsx")
View(exercicio_anova_1)
library(readxl)
exercicio_anova_2 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-2.xlsx")
View(exercicio_anova_2)
# Shapiro Wilk - Distribuicao normal
shapiro.test(Estrato 1)
# A planilha com os dados REFERENTES A ESSA QUESTAO e o exercicio-anova-1.xlsx
library(readxl)
exercicio_anova_1 <- read_excel("C:/Users/User/Downloads/Biologia Quantitativa/exercicio-anova-1.xlsx")
View(exercicio_anova_1)
# Shapiro Wilk - Distribuicao normal
shapiro.test(Estrato 1)
# Shapiro Wilk - Distribuicao normal
shapiro.test(exercicio_anova_1, 1, 1:200)
apply(X = exercicio_anova_1[,-c(1,2)], MARGIN = 1, FUN = shapiro.test)
apply( exercicio_anova_1[,-c(1,2)], MARGIN = 1, FUN = shapiro.test)
apply( exercicio_anova_1[,-c(1,2)], MARGIN = 2, FUN = shapiro.test)
apply( exercicio_anova_1[,-c(1)], MARGIN = 2, FUN = shapiro.test)
apply( x = exercicio_anova_1[,-c(1)], MARGIN = 2, FUN = shapiro.test)
jatoba <- c(17, 11, 16, 12)
cagaita <- c(13, 18, 16, 17)
copaiba <- c(16, 16, 19, 21)
araticum <- c(15, 12, 15, 14)
baru <- c(17, 11, 16, 12)
prod <- c(jatoba, cagaita, copaiba, araticum, baru)
fat <- c(rep("jatoba", 4), rep("cagaita", 4), rep("copaiba", 4),
rep("araticum", 4), rep("baru", 4))
frutos <- data.frame(fat, prod)
View(frutos)
plot(prod ~ fat, data = frutos)
shapiro.test(jatoba)
shapiro.test(cagaita)
shapiro.test(copaiba)
shapiro.test(araticum)
shapiro.test(baru)
install.packages("lawstat")
library(lawstat)
levene.test(frutos$prod, group = frutos$fat)
install.packages("lawstat")
levene.test(frutos$prod, group = frutos$fat)
library(lawstat)
levene.test(frutos$prod, group = frutos$fat)
# Homocedasticidade (Variancias comparaveis ou variancias iguais)
# H0 = variancia entre os grupos igual
# levene.test(y = vetor numerico, group = fator dos dados)
library(lawstat)
levene.test(exercicio_anova_1$dados, group = exercicio_anova_1$estratos)
resultado <- aov(prod ~ fat, data = frutos)
summary(resultado)
# variavel dependente
tingui <- c(16, 13, 19, 9, 15, 11, 22, 25, 17, 10, 11, 9, 13, 14, 21)
barbatimao <- c(18, 17, 21, 15, 13, 12, 14, 16, 12, 11, 8, 22, 7, 15, 10)
tamboril <- c(14, 12, 13, 7, 12, 9, 11, 14, 12, 5, 10, 8, 9, 4, 10)
ipe <- c(21, 20, 16, 15, 16, 21, 25, 17, 14, 22, 15, 21, 20, 23, 21)
prod2 <- c(tingui, barbatimao, tamboril, ipe)
prod2
fat2 <- rep(c(rep("tingui", 15), rep("barbatimao",15),
rep("tamboril", 15), rep("ipe", 15)))
fat2
local <- rep(c(rep("grandesertao",5), rep("veadeiros",5),
rep("brasilia",5)),4)
local
frutos2 <- data.frame(fat2, local, prod2)
frutos2
par(mfrow = c(1,2))
plot(prod2 ~ fat2+local, data = frutos2)
setwd("~/R/bioquant-mod1")
asas = c(1.6, 1.5, 1.8, 1.3, 1.2 ,1.8, 1.5, 1.6, 1.7, 1.8, 1.4, 1.3, 1.8, 1.6, 1.7, 1.5, 1.5, 1.1, 2.0 ,1.7, 1.9, 1.6, 1.7, 1.6, 1.4, 1.5, 1.6, 1.5,1.6, 1.7, 1.5, 1.6, 1.6, 1.3, 1.4, 1.5, 1.5, 1.4 ,1.6 ,1.5, 1.4 ,1.5, 1.8 ,1.1, 1.7, 1.4, 1.1, 1.7, 1.6, 1.4)
corpo = c(3.3, 1.8, 4.2, 3.3, 1.3, 1.3, 2.5, 2.3, 4.4, 3.6, 2.3, 2.8, 4.4, 2.1, 2.3, 2.2, 4.3, 4.0, 1.0, 3.4, 2.6, 3.0, 3.1, 3.1, 2.9, 2.6, 3.0, 3.2,3.8, 2.6, 2.0, 2.0, 3.4, 4.0, 2.5, 2.0, 2.2, 4.5, 2.7, 2.1, 3.1 ,3.8,2.6, 2.8, 3.3, 4.6, 2.8, 2.9, 2.3, 2.8)
##Shapiro Wilk - Distribuicao normal
shapiro.test(asas)
shapiro.test(corpo)
##Teste de Levene - Homocedasticidade
library(lawstat)
levene.test(asas)
resultado_regressão = lm(asas~corpo)
resultado_regressão
summary(resultado_regressão)
#3PLOT#
plot(asas~corpo)
#3PLOT#
plot(corpo~asas)
summary(aov(resultado_regressão))
sorvete = c(20,24,24,26,27,27,38,36,39,21,20,19)
tubarões = c(0,0,0,0,0,1,5,6,9,1,0,0)
##Shapiro Wilk - Distribuicao normal
shapiro.test(sorvete)
tubarões = c(0,0,0,0,0,1,5,6,9,1,0,0)
shapiro.test(tubarões)
#p-value = 0.0004587 < 0.05 = dados não normais
plot(tubarões~sorvete)
#p-value = 0.0004587 < 0.05 = dados não normais
plot(tubarões~sorvete)
resultado_regressão2 = lm(tubarões~sorvete)
resultado_regressão2
summary(resultado_regressão2)
##normalidade dos residuos
shapiro.test(resultado_regressão2)
##normalidade dos residuos
shapiro.test(resultado_regressão2$residuals)
dados <- data.frame(tubarões,sorvete)
View(dados)
dados
dados2 <- data.frame(tubarões,sorvete)
dados2
dados1 <- data.frame(asas,corpo)
dados1
plot (tubarões ~ sorvete,pch=16 ,data = dados2)
abline(resultado_regressão2,col="red")
#PLOT#
plot(asas,corpo)
##plot regressão
plot (asas ~ corpo,pch=16 ,data = dados1)
abline(resultado_regressão1,col="red")
resultado_regressão1 = lm(asas~corpo)
resultado_regressão1
abline(resultado_regressão1,col="red")
##normalidade dos residuos
shapiro.test(resultado_regressão1$residuals)
#plot
plot(asas,corpo)
setwd("~/Bioquant mod 1 (MASTER)/bioquant-mod1-master")
setwd("~/Bioquant mod 1 (MASTER)/bioquant-mod1-master/mod7")
install.packages("vcd")
# Lembram do que o professor ensinou na aula passada? Ent?o, basicamente
# para verificar se os dados seguem uma distribui??o aleat?ria, vamos
# gerar uma distribui??o aleat?ria esperada baseada nos nossos dados
# O pacote goodfit faz isso automaticamente pra gente:
install.packages("vcd")
library(vcd)
extinctData = read.csv(url("http://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter08/chap08e6MassExtinctions.csv"))
View(extinctData)
?goodfit
